{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_워드 임베딩.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjJHd8yOc0pRtMIy56e8xM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PBHPBH/Machine_Learning/blob/NLP/7_%EC%9B%8C%EB%93%9C_%EC%9E%84%EB%B2%A0%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUXvvehnJhTx",
        "outputId": "58c93fe0-bec0-4e93-e640-661a86a6f409"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "464JnUeXUdic"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk\n",
        "!pip install JPype1\n",
        "!pip install rhinoMorph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yvGE0AHUnUZ",
        "outputId": "714ce4bd-b844-4754-8220-74502e8f1e45"
      },
      "source": [
        "#Word2Vec – 학습할 텍스트 읽기\n",
        "import os.path\n",
        "embedding_dim = 50 # 임베딩 차원수 설정\n",
        "filepath = '/content/gdrive/My Drive/pytest/'\n",
        "os.chdir(filepath) # 경로 설정\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "with open('wiki_test.txt', 'r', encoding='utf-8') as f: # 테스트용 파일 읽기\n",
        "    data = f.read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Directory: /content/gdrive/My Drive/pytest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjeuTlTYVM7r",
        "outputId": "156468d6-8d95-48d0-b993-6f2cdcb57f64"
      },
      "source": [
        "#Word2Vec – 문장단위 분리 및 형태소분석기 기동\n",
        "import rhinoMorph\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sent_data = sent_tokenize(data) # 문장 단위 분리\n",
        "rn = rhinoMorph.startRhino() # RHINO 기동\n",
        "print('type:', type(sent_data))\n",
        "print('length:', len(sent_data)) # 전체 문장의 개수\n",
        "print('sentence sample:', sent_data[:20]) # 형태소 분석 전 모습"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "filepath:  /usr/local/lib/python3.7/dist-packages\n",
            "classpath:  /usr/local/lib/python3.7/dist-packages/rhinoMorph/lib/rhino.jar\n",
            "RHINO started!\n",
            "type: <class 'list'>\n",
            "length: 11977\n",
            "sentence sample: ['<doc id=\"5\" url=\"https://ko.wikipedia.org/wiki?curid=5\" title=\"지미 카터\">\\n지미 카터\\n\\n제임스 얼 \"지미\" 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39번째 대통령 (1977년 ~ 1981년)이다.', '지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.', '조지아 공과대학교를 졸업하였다.', '그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다.', '1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다.', '그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.', '1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다.', '대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다.', '조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.', '1976년 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워, 포드를 누르고 당선되었다.', '카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다.', '카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다.', '그러나 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다.', '1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다.', '또한 소련과 제2차 전략 무기 제한 협상에 조인했다.', '카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다.', '<!DOCTYPE tei.2  SYSTEM \"c:굎gml괺td굏ei2.dtd\" [\\n        <!ENTITY % TEI.corpus \"INCLUDE\">\\n        <!ENTITY % TEI.extensions.ent SYSTEM \"sejong1.ent\">\\n        <!ENTITY % TEI.extensions.dtd SYSTEM \"sejong1.dtd\">\\n    ]>\\n<tei.2>\\n<teiHeader>\\n<fileDesc>\\n   <titleStmt>\\n      <title>조선일보 90년 인터뷰기사</title>\\n      <author>박태준외, 기자들</author>\\n      <sponsor>대한민국 문화관광부</sponsor>\\n      <respStmt><resp>전자/표준화</resp>\\n            <name>고려대학교 민족문화연구원</name>\\n      </respStmt>\\n   </titleStmt>\\n   <extent> 55692어절</extent>\\n   <publicationStmt>\\n      <distributor>국립국어연구원</distributor>\\n      <idno>2ba90a03.hwp</idno>\\n      <availability><p>배포 불가</p></availability>\\n   </publicationStmt>\\n   <sourceDesc><p>원전 : 조선일보 인터뷰기사를 CTS파일에서 전자파일화.</p></sourceDesc>\\n</fileDesc>\\n<encodingDesc>\\n   <projectDesc><p>21세기 세종계획 2차년도 말뭉치 구축</p></projectDesc>\\n\\n   <samplingDecl><p>CTS파일을 전자파일화.</p></samplingDecl>\\n   <editorialDecl>\\n      <normalization><p>21세기 세종계획 말뭉치 문헌 입력 지침에 따름</p></normalization>\\n   </editorialDecl>\\n</encodingDesc>\\n<profileDesc>\\n   <creation><date>1990</date></creation>\\n   <samplingDecl><p>CTS파일을 전자파일화.</p></samplingDecl>\\n   <langUsage>\\n         <language id=KO usage=99>한국어, 표준어</language>\\n   </langUsage>\\n   <particDesc>\\n         <person id=P1 sex=?', 'age=?>박태준외</person>\\n         <person id=P2 sex=?', 'age=?>기자들</person>\\n   </particDesc>\\n   <settingDesc>\\n         <setting who=\\'P1 P2\\'>\\n         <p>1990년 조선일보 인터뷰기사를 전자파일로 입수</p>\\n         </setting>\\n   </settingDesc>\\n   <textClass>\\n         <catRef scheme=\\'SJ21\\' target=\\'M2104\\'></catRef>  \\n   </textClass>\\n</profileDesc>\\n<revisionDesc>\\n  <respStmt>\\n        <resp>프로젝트책임자</resp><name>김흥규</name>\\n  </respStmt>\\n   <change><date>1994</date><respStmt><name>한국언론연구원</name></respStmt>\\n        <item>CTS파일을 전자파일화</item>\\n   </change>\\n   <change><date>1996/08</date><respStmt><name>최민우</name></respStmt>\\n        <item>헤더붙임</item>\\n   </change>\\n  <change><date>1999/11</date><respStmt><name>박병선</name></respStmt>\\n        <item>파일 포맷 변환, 교정, 세종 21 계획 헤더 붙임, 마킹, 검토</item>\\n   </change>\\n</revisionDesc>\\n</teiHeader>\\n\\n<text>\\n<group>\\n<text><body>\\n<source>\\n  <date>1990/01/06</date>\\n  <page>02</page>\\n</source>\\n<head>\"정치 신뢰회복 최선 다하겠다\" / 박태준 민정대표 일문일답</head>\\n<head>\"당내 융화-결속엔 별 문제 없어 / 민주화 촉진-경제난 극복에 맞춰 당운영\"</head>\\n<p>민정당의 신임 박태준대표위원은 \"기왕에 정치일선에 나선이상 신명을 바쳐 저하된 정치의 신뢰를 회복하는 데 최선을 다하겠다\"고 첫 소감을 말했다.</p>\\n<p>5일 오후 노태우대통령으로부터 대표위원 임명통보를 받은 뒤 오후 4 시쯤 민정당사에 도착, 곧바로 가진 기자회견에서 그는 밝은 표정으로 질문에 응했으나 정계개편등 중요 현안에 대해서는 \"앞으로 공부를 더해 답하겠다\"는 말로 답변을 대신했다.</p>\\n<p>- 어려운 시기에 대표위원을 맡았는데….</p>\\n<p>\"해외여행에서 돌아오자마자 대임을 맡게 돼, 아직까지 생각을 정리해 본 적은 없습니다.', '그러나 평소 정치의 신뢰가 대단히 저하됐다고 생각해  왔기 때문에 동료의원들의 협조를 얻어 정치의 신뢰를 회복시키고 국민들이 정치걱정하지 않고 생업에 충실할 수 있도록 최선을 다하겠습니다.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1EzIt9sVSj0",
        "outputId": "111b5538-1c08-40db-e7e9-1db98c86ce17"
      },
      "source": [
        "#Word2Vec – 텍스트의 형태소 분석\n",
        "total_lines = len(sent_data)\n",
        "cnt = 0\n",
        "with open(filepath+'word2vec/wiki202003_nationalcorpus_naverratings_morphed.txt', 'w', encoding='utf-8') as f:\n",
        "    for data_each in sent_data:\n",
        "        morphed_data_each = rhinoMorph.onlyMorph_list(rn, data_each, pos=['NNG', 'NNP', 'NP', 'VV', 'VA', 'XR', 'IC', 'MM', 'MAG', 'MAJ'])\n",
        "        joined_data_each = ' '.join(morphed_data_each)\n",
        "        if joined_data_each:\n",
        "            f.write(joined_data_each + '\\n')\n",
        "        cnt += 1\n",
        "        if (cnt % 1000) == 0: # 진행 정도 확인을 위해 1000번째 문장마다 확인\n",
        "            print(round(cnt/total_lines * 100, 3), '%')\n",
        "print('Morphological Analysis Completed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.349 %\n",
            "16.699 %\n",
            "25.048 %\n",
            "33.397 %\n",
            "41.747 %\n",
            "50.096 %\n",
            "58.445 %\n",
            "66.795 %\n",
            "75.144 %\n",
            "83.493 %\n",
            "91.843 %\n",
            "Morphological Analysis Completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZAhaqi2V-qW",
        "outputId": "816de481-8238-4030-b9ab-40f77f939457"
      },
      "source": [
        "#Word2Vec – 형태소 분석 결과를 읽어 리스트로 만들기\n",
        "def read_data(filename, encoding='utf-8'): # 읽기 함수 정의\n",
        "    with open(filename, 'r', encoding=encoding) as f:\n",
        "        data = [line.split(' ') for line in f.read().splitlines()]\n",
        "    return data\n",
        "data = read_data(filepath + 'word2vec/wiki202003_nationalcorpus_naverratings_morphed.txt', 'utf-8')\n",
        "print(len(data))\n",
        "print(type(data))\n",
        "print(data[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11976\n",
            "<class 'list'>\n",
            "[['URL', '미', '카터', '미', '카터', '제임스', '얼', '미', '카터', '주니어', '민주당', '출신', '미국', '대통령'], ['미', '카터', '조지아', '섬터', '카운티', '마을', '태어나'], ['조지아', '공과대학', '교', '졸업']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GLvzVf4zW7XC",
        "outputId": "0ed25153-c024-4914-95f2-2ca2f73a46e2"
      },
      "source": [
        "filepath"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/pytest/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPUr5bEjXpsi",
        "outputId": "a84069d8-1903-4641-e36e-7e6d4748f13b"
      },
      "source": [
        "#Word2Vec – 임베딩 구성\n",
        "from gensim.models import Word2Vec\n",
        "os.chdir(filepath+'word2vec/')\n",
        "# size: 벡터의 차원, window: 컨텍스트 윈도우의 크기, min_count: 단어 최소 빈도, workers: 학습을 위한 프로세스 수, sg: 0은 CBOW, 1은 skip-gram\n",
        "model = Word2Vec(sentences=data, size=embedding_dim, window=10, min_count=5, workers=4, sg=1)\n",
        "model.save('embedding_window10_mincnt5_skipgram.model')\n",
        "print('Completed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on29WS2dYGYM"
      },
      "source": [
        "#Word2Vec – 임베딩 값 저장\n",
        "words = list(model.wv.vocab)\n",
        "with open('embedding_window10_mincnt5_skipgram.txt', 'w') as f:\n",
        "    for word in words:\n",
        "        data = model.wv[word].tolist() # 현재 단어의 임베딩 값을 가져온다\n",
        "        print('data_pre:', data) # 현재 단어의 임베딩 값을 출력해본다\n",
        "\n",
        "        data.insert(0, word) # 시작 부분에 해당 단어를 넣는다\n",
        "        print('data_after:', data) # 현재 단어의 이름과 함께 임베딩 값을 출력해본다\n",
        "\n",
        "        for item in data: # 단어 이름부터 시작하여 각 벡터의 값을 저장한다\n",
        "            f.write(\"%s \" % item)\n",
        "        f.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfsYZEh3YXai",
        "outputId": "ffa555e6-008a-42df-c7f9-f79c36f30ff4"
      },
      "source": [
        "#Word2Vec – 유사어 찾기\n",
        "model = Word2Vec.load('embedding_window10_mincnt5_skipgram.model')\n",
        "print('--- 유사단어 출력 ---')\n",
        "similarWords = model.wv.most_similar(positive=['행복', '웃음', '밝'], topn=3)\n",
        "print(similarWords) # [('흐뭇', 0.8801068067550659), ('마음', 0.8738192319869995), ('해맑', 0.8424177169799805)]\n",
        "\n",
        "word = []\n",
        "for similarWord in similarWords: # 유사도값을 제외하고 단어만 모은다\n",
        "    word.append(similarWord[0])\n",
        "print(word) # ['흐뭇', '마음', '해맑']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 유사단어 출력 ---\n",
            "[('일어서', 0.9741085171699524), ('깜짝', 0.9731009602546692), ('따뜻하', 0.972411572933197)]\n",
            "['일어서', '깜짝', '따뜻하']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRlJM0nUYiK6",
        "outputId": "62688671-73a1-467d-8358-fe27c28b86c4"
      },
      "source": [
        "#Word2Vec – 두 단어 사이의 유사도 계산\n",
        "print('--- 두 단어의 유사도 계산 ---')\n",
        "print('한국과 일본:', model.wv.similarity('한국', '일본'))\n",
        "print('한국과 미국:', model.wv.similarity('한국', '미국'))\n",
        "print('한국과 중국:', model.wv.similarity('한국', '중국'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 두 단어의 유사도 계산 ---\n",
            "한국과 일본: 0.6982431\n",
            "한국과 미국: 0.75216246\n",
            "한국과 중국: 0.7944958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmZuegCiYt6m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}