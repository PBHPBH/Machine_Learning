{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_텍스트 이진 분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0dqJcl38mL3ze1Ga9O/5C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PBHPBH/Machine_Learning/blob/NLP/6_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%9D%B4%EC%A7%84_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWmTH4AnGqO7",
        "outputId": "8619599a-fa37-4445-a22d-560b15edb516"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "imdb_dir = '/content/gdrive/My Drive/pytest/aclImdb_v1_small/aclImdb/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgAHRZmWH3Kr"
      },
      "source": [
        "#Train Data Loading\n",
        "import os\n",
        "train_dir = os.path.join(imdb_dir, 'train') # aclimdb 폴더의 훈련 데이터 내용을 가져온다\n",
        "labels = [] ; texts = [] # labels와 texts 라는 두 개의 빈 리스트를 만든다\n",
        "\n",
        "for label_type in ['neg', 'pos']: # train 폴더에 있는 pos 12,500 + neg 12,500 개의 데이터를 읽는다\n",
        "    dir_name = os.path.join(train_dir, label_type) # neg와 pos 폴더 각각에 접근한다\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt': # 마지막 4 글자가 .txt 로 끝나는지를 확인한다\n",
        "            f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
        "            texts.append(f.read()) # 텍스트를 읽어서 texts 리스트에 연결한다\n",
        "            f.close()\n",
        "            if label_type == 'neg': # 만약 현재 폴더가 neg 폴더라면\n",
        "                labels.append(0) # texts와 같은 순서의 labels 리스트에 0을 저장한다\n",
        "            else:\n",
        "                labels.append(1) # pos 폴더라면 같은 순서의 labels 리스트에 1을 저장\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6DGfiJRJnmk",
        "outputId": "645e3196-935a-4fb9-ca52-c840dc89cae5"
      },
      "source": [
        "#Data 확인\n",
        "print('texts 0:', texts[0])\n",
        "print('texts len:', len(texts))\n",
        "\n",
        "print('labels 0:', labels[0])\n",
        "print('labels len:', len(labels))\n",
        "\n",
        "print('texts type', type(texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "texts 0: Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
            "texts len: 60\n",
            "labels 0: 0\n",
            "labels len: 60\n",
            "texts type <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqyu6znCK8zG"
      },
      "source": [
        "#Data Tokenizing\n",
        "\n",
        "#텍스트에 사용된 단어의 조류를 빈도 순으로 정렬하는 작업을 수행한다\n",
        "%tensorflow_version 2.x\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "validation_ratio = math.floor(len(texts)*0.3) # 최적 모델 판정을 위한 검증 샘플은 전체의 30%로 한다\n",
        "max_words = 10000   #데이터셋에서 가장 빈도 높은 9,999개의 단어만 사용한다\n",
        "maxlen = 200   #항상 각 문장의 길이가 200 단어가 되도록 고정한다\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words) #상위빈도 max_words개의 단어를 추려내는 Tokenizer객체 생성\n",
        "tokenizer.fit_on_texts(texts)   #texts 내용에 대한 단어 인덱스를 구축한다. 사용할 단어가 결정된다.\n",
        "word_index = tokenizer.word_index   #단어와 인덱스의 쌍을 가져온다\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqzfRFp9MYWS",
        "outputId": "8fa703ec-b1b2-4229-ccf5-1a2898c9bef3"
      },
      "source": [
        "#Tokenizing 결과확인\n",
        "print('전체에서 %s개의 고유한 토큰을 찾았습니다.' %len(word_index))\n",
        "print('word_index_type: ', type(word_index))\n",
        "print('word_index:', word_index)\n",
        "#아직은 max_words(9,999)개가 아닌 전체 88,532개의 단어-빈도 쌍을 보여준다\n",
        "#texts_to_sequences()를 거쳐야 각 문장에서 빈도순위 max_words(9,999)위까지만 남는다\n",
        "\n",
        "#word index는 Dictionary 타입이며,\n",
        "#토큰으로 선정된 각 단어에 대하여 index가 배당된 것을 알 수 있다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체에서 2828개의 고유한 토큰을 찾았습니다.\n",
            "word_index_type:  <class 'dict'>\n",
            "word_index: {'the': 1, 'and': 2, 'a': 3, 'of': 4, 'to': 5, 'br': 6, 'is': 7, 'in': 8, 'i': 9, 'this': 10, 'it': 11, 'that': 12, 'for': 13, 'film': 14, 'was': 15, 'are': 16, 'with': 17, 'but': 18, 'movie': 19, 'as': 20, 'you': 21, 'not': 22, 'at': 23, 'he': 24, 'on': 25, 'be': 26, 'one': 27, 'have': 28, 'an': 29, 'all': 30, 'his': 31, 'like': 32, 'good': 33, 'has': 34, 'or': 35, 'some': 36, 'just': 37, 'so': 38, 'even': 39, 'who': 40, 'by': 41, 'my': 42, 'story': 43, 'about': 44, 'from': 45, 'out': 46, 'time': 47, 'when': 48, \"it's\": 49, 'very': 50, 'they': 51, 'no': 52, 'really': 53, 'if': 54, 'acting': 55, 'there': 56, 'every': 57, 'him': 58, 'ever': 59, 'most': 60, 'more': 61, 'great': 62, 'people': 63, 'other': 64, 'how': 65, 'also': 66, 'her': 67, 'too': 68, 'would': 69, 'bad': 70, 'their': 71, 'your': 72, 'made': 73, 'what': 74, 'she': 75, 'stanley': 76, 'can': 77, 'had': 78, 'me': 79, 'make': 80, 'plot': 81, 'characters': 82, 'only': 83, 'read': 84, 'up': 85, 'love': 86, 'will': 87, 'character': 88, 'well': 89, 'into': 90, 'director': 91, 'these': 92, 'any': 93, 'movies': 94, 'red': 95, 'actors': 96, 'do': 97, 'here': 98, 'first': 99, 'iris': 100, 'after': 101, \"don't\": 102, 'see': 103, 'many': 104, 'such': 105, 'should': 106, 'which': 107, 'its': 108, 'we': 109, 'two': 110, 'again': 111, 'were': 112, 'then': 113, \"can't\": 114, 'think': 115, 'been': 116, 'over': 117, 'life': 118, 'say': 119, 'cast': 120, 'does': 121, 'giallo': 122, 'seen': 123, 'could': 124, 'much': 125, 'way': 126, 'though': 127, 'least': 128, 'find': 129, 'interesting': 130, 'never': 131, 'watching': 132, 'because': 133, 'makes': 134, 'real': 135, 'family': 136, 'times': 137, \"he's\": 138, 'films': 139, 'job': 140, 'yet': 141, 'scene': 142, 'better': 143, 'than': 144, 'new': 145, 'them': 146, 'end': 147, 'still': 148, 'line': 149, 'before': 150, '10': 151, 'jane': 152, 'high': 153, 'fonda': 154, 'walken': 155, 'queen': 156, 'know': 157, 'our': 158, 'where': 159, 'camera': 160, 'production': 161, 'through': 162, 'overall': 163, 'score': 164, 'pretty': 165, 'style': 166, 'get': 167, 'go': 168, 'seeing': 169, 'another': 170, 'nothing': 171, 'came': 172, 'watch': 173, 'enough': 174, 'robert': 175, 'work': 176, \"isn't\": 177, 'each': 178, 'man': 179, 'whole': 180, 'off': 181, 'feel': 182, 'why': 183, 'far': 184, 'role': 185, 'being': 186, 'minutes': 187, 'effects': 188, 'violence': 189, 'terrible': 190, 'lines': 191, 'beautiful': 192, 'script': 193, 'young': 194, 'school': 195, 'seven': 196, 'down': 197, 'few': 198, 'almost': 199, 'money': 200, 'art': 201, 'need': 202, 'said': 203, 'thing': 204, 'bit': 205, \"didn't\": 206, 'genre': 207, 'recommend': 208, 'working': 209, 'while': 210, 'human': 211, 'ending': 212, 'horror': 213, 'world': 214, 'both': 215, 'those': 216, 'left': 217, \"there's\": 218, 'reason': 219, 'night': 220, 'action': 221, 'actually': 222, 'home': 223, 'part': 224, 'something': 225, 'excellent': 226, 'written': 227, 'hard': 228, 'already': 229, 'saw': 230, 'madsen': 231, 'take': 232, 'others': 233, 'write': 234, \"i'm\": 235, 'performances': 236, 'de': 237, 'niro': 238, 'although': 239, 'done': 240, 'tale': 241, 'without': 242, 'house': 243, 'seems': 244, 'same': 245, 'deniro': 246, 'show': 247, 'understand': 248, 'memorable': 249, 'italian': 250, 'kills': 251, 'evelyn': 252, 'bromwell': 253, 'making': 254, 'might': 255, 'however': 256, 'let': 257, 'worst': 258, 'give': 259, 'cannot': 260, 'put': 261, 'type': 262, 'society': 263, 'going': 264, 'mean': 265, 'used': 266, 'given': 267, 'now': 268, 'waste': 269, 'special': 270, 'always': 271, 'fan': 272, 'away': 273, 'sound': 274, 'low': 275, 'drama': 276, 'instead': 277, 'performance': 278, 'ok': 279, 'watched': 280, 'years': 281, 'probably': 282, 'later': 283, 'title': 284, 'care': 285, 'unbelievable': 286, 'imdb': 287, 'illiterate': 288, \"film's\": 289, 'illiteracy': 290, 'course': 291, 'hollywood': 292, 'gun': 293, 'novel': 294, \"doesn't\": 295, 'best': 296, 'quite': 297, 'place': 298, 'must': 299, 'hot': 300, 'fact': 301, '1972': 302, 'cinema': 303, 'black': 304, 'original': 305, 'bouchet': 306, \"iris'\": 307, 'feelings': 308, 'unfortunately': 309, 'seem': 310, 'level': 311, 'future': 312, 'lot': 313, 'annoying': 314, 'decent': 315, 'everything': 316, 'three': 317, 'believe': 318, 'us': 319, '3': 320, 'want': 321, 'drug': 322, 'boring': 323, 'war': 324, 'become': 325, '2': 326, 'worth': 327, 'may': 328, 'music': 329, 'arnold': 330, 'happy': 331, 'supporting': 332, 'found': 333, 'rape': 334, 'got': 335, 'father': 336, 'ask': 337, 'class': 338, 'totally': 339, 'beginning': 340, 'gives': 341, 'guess': 342, 'favorite': 343, 'kind': 344, \"won't\": 345, 'simply': 346, 'shot': 347, 'things': 348, 'come': 349, 'sub': 350, 'nice': 351, 'poorly': 352, 'thought': 353, 'often': 354, 'did': 355, 'needs': 356, 'gets': 357, 'face': 358, 'stories': 359, 'wonder': 360, 'back': 361, 'little': 362, 'looking': 363, \"you'll\": 364, 'save': 365, 'tells': 366, 'perfect': 367, 'looks': 368, 'rather': 369, 'christopher': 370, 'puss': 371, 'daughter': 372, 'unique': 373, 'year': 374, 'sister': 375, 'female': 376, 'barbara': 377, 'personal': 378, 'murders': 379, 'teachers': 380, 'sex': 381, 'factory': 382, 'relations': 383, 'example': 384, 'general': 385, 'stars': 386, 'believable': 387, 'clearly': 388, 'techniques': 389, 'wanted': 390, 'feeling': 391, 'anything': 392, 'truly': 393, 'earth': 394, 'living': 395, 'reality': 396, 'own': 397, 'tell': 398, 'friends': 399, 'awkward': 400, 'second': 401, 'editing': 402, 'effect': 403, 'appears': 404, '4': 405, 'sense': 406, 'gave': 407, 'fast': 408, 'big': 409, 'vosloo': 410, 'star': 411, 'took': 412, 'leaves': 413, \"couldn't\": 414, 'tristan': 415, 'age': 416, 'picture': 417, 'doing': 418, '1': 419, 'trying': 420, 'move': 421, 'stylish': 422, 'effort': 423, \"i've\": 424, \"you're\": 425, 'michael': 426, 'piece': 427, 'parts': 428, 'girls': 429, 'anyone': 430, \"fonda's\": 431, 'mostly': 432, 'true': 433, 'around': 434, \"barker's\": 435, 'case': 436, 'women': 437, 'hope': 438, 'romance': 439, 'main': 440, 'turkish': 441, 'names': 442, 'experience': 443, 'american': 444, 'directing': 445, 'price': 446, 'poor': 447, 'goes': 448, 'either': 449, 'funny': 450, 'perhaps': 451, 'generally': 452, 'drugs': 453, 'couple': 454, 'male': 455, 'someone': 456, 'actresses': 457, 'subject': 458, 'serious': 459, 'possibly': 460, 'himself': 461, 'says': 462, 'chace': 463, 'scenes': 464, 'viewer': 465, 'fighting': 466, 'post': 467, 'help': 468, 'viewers': 469, 'heart': 470, 'songs': 471, 'fun': 472, 'enjoyable': 473, 'dancing': 474, 'children': 475, 'emilio': 476, 'kitty': 477, 'suddenly': 478, 'gorgeous': 479, 'among': 480, 'grave': 481, 'beauty': 482, 'gothic': 483, 'incredibly': 484, 'brilliant': 485, 'husband': 486, 'references': 487, 'public': 488, 'theatre': 489, 'industrial': 490, 'workers': 491, 'traditionally': 492, 'adult': 493, 'starts': 494, 'comedy': 495, 'audience': 496, 'cinematography': 497, 'writers': 498, 'lots': 499, \"i'd\": 500, 'wasted': 501, 'worse': 502, 'days': 503, 'loaded': 504, 'enjoy': 505, '5': 506, 'amount': 507, 'stupid': 508, 'writer': 509, 'slow': 510, 'am': 511, 'direction': 512, 'considering': 513, 'enjoyed': 514, 'convincing': 515, 'storyline': 516, 'sure': 517, 'lack': 518, 'potential': 519, \"wasn't\": 520, 'giving': 521, 'attention': 522, \"wouldn't\": 523, 'average': 524, 'vinnie': 525, 'knows': 526, 'looked': 527, 'shy': 528, 'seemed': 529, 'fake': 530, 'edward': 531, 'furlong': 532, '20': 533, 'crap': 534, 'everybody': 535, 'unless': 536, 'last': 537, 'window': 538, \"i'll\": 539, 'contrived': 540, 'look': 541, 'corey': 542, 'information': 543, 'playing': 544, 'sebastian': 545, 'images': 546, 'colors': 547, 'opinion': 548, 'budget': 549, 'sometimes': 550, 'yourself': 551, 'terribly': 552, 'source': 553, 'oh': 554, 'god': 555, 'suck': 556, 'yes': 557, 'killing': 558, 'liked': 559, 'adaptation': 560, 'reading': 561, 'union': 562, 'street': 563, 'felt': 564, 'top': 565, 'sensitive': 566, 'issues': 567, 'dvd': 568, 'interested': 569, 'thinking': 570, 'talents': 571, 'master': 572, 'amateur': 573, 'lets': 574, 'mr': 575, 'skill': 576, 'less': 577, \"that's\": 578, 'law': 579, \"aren't\": 580, 'appear': 581, 'mention': 582, 'else': 583, 'takes': 584, 'predictable': 585, 'name': 586, 'released': 587, 'heard': 588, 'check': 589, 'day': 590, 'english': 591, 'thrown': 592, 'having': 593, 'redeeming': 594, 'self': 595, 'use': 596, 'tried': 597, 'sounded': 598, 'weird': 599, 'positive': 600, 'laugh': 601, 'mess': 602, 'stage': 603, 'completely': 604, 'woman': 605, 'person': 606, 'definitely': 607, 'period': 608, 'pure': 609, 'early': 610, 'becomes': 611, 'hair': 612, 'masterpiece': 613, 'idea': 614, 'exercise': 615, 'lives': 616, 'means': 617, 'hitchcock': 618, 'especially': 619, 'europe': 620, 'germany': 621, 'mixed': 622, 'emotional': 623, 'middle': 624, 'regarding': 625, 'strong': 626, 'cat': 627, 'unlike': 628, 'corin': 629, 'dance': 630, 'magic': 631, 'adults': 632, \"miraglia's\": 633, 'mesmerizing': 634, 'killer': 635, 'uncanny': 636, 'lady': 637, 'begins': 638, 'complex': 639, 'herrings': 640, \"she's\": 641, 'greatest': 642, 'sybil': 643, 'danning': 644, 'importance': 645, 'john': 646, 'williams': 647, 'tenderness': 648, 'lovely': 649, 'south': 650, 'gialli': 651, 'forward': 652, 'creepy': 653, 'overwhelming': 654, 'elements': 655, 'atmosphere': 656, 'lead': 657, 'castle': 658, 'indeed': 659, 'haunting': 660, 'frightening': 661, 'screen': 662, 'afraid': 663, 'roles': 664, 'students': 665, 'keisha': 666, 'musical': 667, 'therefore': 668, 'singing': 669, 'classic': 670, 'boots': 671, 'ogre': 672, 'cares': 673, 'widow': 674, 'difficult': 675, 'small': 676, 'unable': 677, 'dead': 678, 'system': 679, 'worker': 680, 'realm': 681, 'teaching': 682, 'literacy': 683, 'student': 684, 'teenage': 685, 'pig': 686, 'terrific': 687, 'absurd': 688, 'orchestra': 689, 'turned': 690, 'insane': 691, 'crazy': 692, 'stays': 693, 'era': 694, 'easy': 695, 'seriously': 696, 'expected': 697, 'resolution': 698, 'alas': 699, 'horrific': 700, 'considered': 701, 'brought': 702, 'disgusting': 703, 'types': 704, 'taste': 705, 'happen': 706, 'sequence': 707, 'cheesy': 708, 'jump': 709, 'cuts': 710, 'cut': 711, 'specific': 712, 'disturbing': 713, 'somewhat': 714, 'grab': 715, 'swallow': 716, 'needed': 717, 'form': 718, 'torture': 719, 'abroad': 720, 'keep': 721, 'trust': 722, 'stop': 723, 'vile': 724, 'please': 725, 'flaws': 726, 'stuff': 727, 'filmed': 728, 'bored': 729, 'uses': 730, 'hour': 731, '50': 732, 'dialogs': 733, 'finally': 734, 'recent': 735, 'town': 736, 'background': 737, 'desired': 738, 'actor': 739, 'lousy': 740, 'otherwise': 741, 'unnecessary': 742, 'continuity': 743, 'entertainment': 744, 'motives': 745, 'fetched': 746, 'setting': 747, \"what's\": 748, 'behavior': 749, 'kids': 750, 'random': 751, 'questions': 752, 'path': 753, 'paying': 754, 'wants': 755, 'substances': 756, 'political': 757, 'hand': 758, 'cheap': 759, 'set': 760, 'jones': 761, 'reputation': 762, 'total': 763, 'ago': 764, 'sleep': 765, 'plus': 766, 'side': 767, 'appreciate': 768, 'straight': 769, 'video': 770, 'void': 771, 'costs': 772, 'executed': 773, 'anymore': 774, 'spot': 775, 'shattered': 776, 'fired': 777, 'spare': 778, 'par': 779, 'manner': 780, 'half': 781, 'assed': 782, 'christ': 783, 'warn': 784, 'avoid': 785, 'writing': 786, 'rule': 787, 'text': 788, 'account': 789, 'express': 790, \"large's\": 791, 'apparently': 792, 'called': 793, 'named': 794, 'cole': 795, 'points': 796, 'weak': 797, 'actress': 798, 'drive': 799, 'full': 800, 'eye': 801, 'against': 802, 'comment': 803, 'horrible': 804, 'insightful': 805, 'awful': 806, 'begin': 807, 'standard': 808, 'honestly': 809, 'expect': 810, \"we'll\": 811, 'endure': 812, 'shouting': 813, 'hallmark': 814, 'neither': 815, 'involved': 816, 'mediocre': 817, 'pat': 818, \"'union\": 819, \"street'\": 820, 'fails': 821, 'angle': 822, 'england': 823, 'anger': 824, 'truth': 825, 'inspiring': 826, 'soundtrack': 827, 'accept': 828, 'tales': 829, 'leading': 830, 'protagonists': 831, 'issue': 832, 'lost': 833, 'covered': 834, 'book': 835, 'decide': 836, 'credits': 837, 'wait': 838, 'literally': 839, 'america': 840, 'crew': 841, 'further': 842, 'international': 843, 'produce': 844, 'bottom': 845, 'present': 846, 'flick': 847, 'ways': 848, 'masterpieces': 849, 'thriller': 850, 'includes': 851, 'sole': 852, 'result': 853, 'usually': 854, 'degree': 855, 'damn': 856, \"shouldn't\": 857, 'coffeshop': 858, 'requires': 859, 'plays': 860, 'intelligent': 861, 'talent': 862, 'dialog': 863, 'herself': 864, 'moves': 865, 'pace': 866, 'ill': 867, 'equally': 868, 'ten': 869, 'review': 870, 'require': 871, 'extremely': 872, 'jesse': 873, 'metcalfe': 874, 'mark': 875, 'son': 876, 'settings': 877, 'expectations': 878, 'except': 879, \"tristan's\": 880, 'leave': 881, 'past': 882, 'event': 883, 'graduation': 884, 'celebration': 885, 'large': 886, 'constant': 887, 'tricks': 888, 'motion': 889, 'perspective': 890, 'despite': 891, 'relative': 892, 'respect': 893, 'bigger': 894, 'based': 895, 'scores': 896, 'incredible': 897, 'attractive': 898, 'buying': 899, 'renting': 900, 'free': 901, 'added': 902, 'murder': 903, 'conflicts': 904, 'ultimately': 905, 'five': 906, 'note': 907, 'thru': 908, 'happened': 909, 'rented': 910, 'knowledge': 911, 'forget': 912, 'shame': 913, 'native': 914, 'speakers': 915, 'play': 916, 'quality': 917, 'portrays': 918, 'individual': 919, 'unfortunate': 920, 'thus': 921, 'convoluted': 922, 'final': 923, 'gunfight': 924, \"'bad'\": 925, 'delivered': 926, 'ability': 927, 'failure': 928, 'teeth': 929, 'dimensional': 930, 'ball': 931, 'guns': 932, 'member': 933, 'girl': 934, 'f': 935, 'nearly': 936, 'single': 937, 'produced': 938, 'different': 939, \"haven't\": 940, 'wish': 941, 'april': 942, 'nathalie': 943, 'kelley': 944, 'aspect': 945, 'able': 946, '1969': 947, 'date': 948, 'late': 949, '70s': 950, 'distorted': 951, 'using': 952, 'accompanied': 953, 'sort': 954, 'obviously': 955, 'quickly': 956, 'bore': 957, 'catch': 958, 'word': 959, 'stay': 960, 'indifferent': 961, 'van': 962, 'consider': 963, 'loved': 964, 'theatrical': 965, 'famous': 966, 'language': 967, 'survive': 968, 'immediately': 969, 'white': 970, 'vanquished': 971, 'victims': 972, 'ambiguous': 973, 'change': 974, 'today': 975, 'british': 976, 'spies': 977, 'german': 978, 'trains': 979, 'symbol': 980, 'intensity': 981, 'train': 982, 'classical': 983, 'guys': 984, 'principal': 985, 'willing': 986, 'destruction': 987, 'actions': 988, 'moments': 989, 'demonstrative': 990, 'try': 991, 'alone': 992, 'claim': 993, 'flicks': 994, 'blue': 995, 'collar': 996, 'kid': 997, 'remember': 998, \"children's\": 999, 'jason': 1000, \"miller's\": 1001, 'falls': 1002, 'vera': 1003, 'fairytales': 1004, 'kitchen': 1005, 'dancer': 1006, 'together': 1007, 'wall': 1008, 'absolute': 1009, 'gory': 1010, 'fabulous': 1011, 'old': 1012, 'revenge': 1013, 'macabre': 1014, 'grandfather': 1015, 'once': 1016, 'victim': 1017, 'fourteen': 1018, 'successful': 1019, 'moved': 1020, 'recently': 1021, 'compelling': 1022, 'involving': 1023, 'behind': 1024, 'gruesome': 1025, 'nudity': 1026, 'miraglia': 1027, 'recommended': 1028, 'caught': 1029, 'surprise': 1030, 'shows': 1031, 'etc': 1032, 'necessary': 1033, 'earlier': 1034, 'highly': 1035, 'successfully': 1036, 'spine': 1037, 'chilling': 1038, 'genuinely': 1039, 'lush': 1040, 'ravishing': 1041, 'stunningly': 1042, 'outstanding': 1043, 'elegant': 1044, 'painting': 1045, 'fiendish': 1046, 'return': 1047, 'fashion': 1048, 'gem': 1049, 'eyes': 1050, 'wise': 1051, 'figure': 1052, 'laughter': 1053, 'sexy': 1054, 'apart': 1055, 'bruno': 1056, 'praise': 1057, 'areas': 1058, 'leaving': 1059, 'imagine': 1060, 'wife': 1061, 'child': 1062, 'drops': 1063, 'beer': 1064, 'concerning': 1065, 'right': 1066, 'sisters': 1067, 'dream': 1068, 'fine': 1069, 'latrina': 1070, 'natella': 1071, 'imaginable': 1072, 'episode': 1073, \"walken's\": 1074, 'skills': 1075, 'preserved': 1076, 'broadway': 1077, 'everyone': 1078, 'deeply': 1079, 'gay': 1080, 'marriage': 1081, 'conform': 1082, 'social': 1083, 'version': 1084, 'u': 1085, 'mainstream': 1086, 'studio': 1087, 'fairy': 1088, 'king': 1089, 'typical': 1090, 'efforts': 1091, 'deeper': 1092, 'plan': 1093, 'courage': 1094, 'becoming': 1095, 'hell': 1096, 'itself': 1097, 'participation': 1098, 'bring': 1099, 'reasons': 1100, 'superb': 1101, 'whose': 1102, 'waterbury': 1103, 'locale': 1104, 'resulted': 1105, 'ordinary': 1106, 'wondered': 1107, 'adventure': 1108, 'turn': 1109, 'plimpton': 1110, 'fordist': 1111, 'assembly': 1112, 'loses': 1113, 'brother': 1114, 'abusive': 1115, 'conventional': 1116, 'presumably': 1117, 'outside': 1118, 'capitalism': 1119, 'technology': 1120, 'creative': 1121, 'bauhaus': 1122, 'access': 1123, 'monetary': 1124, 'vehicular': 1125, 'open': 1126, 'books': 1127, 'bible': 1128, 'arrangement': 1129, 'absence': 1130, 'refreshing': 1131, \"weren't\": 1132, 'nervous': 1133, 'situation': 1134, 'portrayal': 1135, 'theme': 1136, 'touching': 1137, 'lacking': 1138, 'problems': 1139, 'unnatural': 1140, 'opening': 1141, 'formal': 1142, 'violent': 1143, 'mob': 1144, 'chantings': 1145, 'singers': 1146, 'narrative': 1147, 'eventually': 1148, 'putting': 1149, 'cryptic': 1150, 'dialogue': 1151, 'shakespeare': 1152, 'third': 1153, 'grader': 1154, 'technical': 1155, 'vilmos': 1156, 'zsigmond': 1157, 'sally': 1158, 'kirkland': 1159, 'frederic': 1160, 'forrest': 1161, 'briefly': 1162, 'promise': 1163, 'relatively': 1164, 'editors': 1165, 'wooden': 1166, 'edited': 1167, 'learnt': 1168, 'edit': 1169, 'splash': 1170, 'quick': 1171, \"'flashy'\": 1172, 'edits': 1173, 'meant': 1174, 'symbolic': 1175, 'breakdown': 1176, 'equilibrium': 1177, 'makers': 1178, 'beats': 1179, 'retire': 1180, 'trophy': 1181, 'comparison': 1182, 'insanely': 1183, 'created': 1184, 'existence': 1185, 'question': 1186, 'whether': 1187, 'humans': 1188, 'disgusted': 1189, 'ourselves': 1190, 'progress': 1191, 'species': 1192, 'universe': 1193, 'sincerely': 1194, 'hurts': 1195, 'ashamed': 1196, 'emphasize': 1197, 'global': 1198, 'responsibility': 1199, 'creating': 1200, 'prevent': 1201, 'creation': 1202, 'gross': 1203, 'distortions': 1204, 'embarrassment': 1205, 'sleeps': 1206, 'knowing': 1207, 'monsters': 1208, 'shark': 1209, 'attack': 1210, 'hilarious': 1211, 'crosses': 1212, 'dimension': 1213, 'death': 1214, 'shamelessly': 1215, 'sickening': 1216, 'point': 1217, 'shaky': 1218, 'buzz': 1219, 'rush': 1220, 'swerve': 1221, 'fancy': 1222, 'meticulously': 1223, 'repetitive': 1224, 'tortures': 1225, 'excrement': 1226, 'personally': 1227, 'shoulders': 1228, 'shake': 1229, 'submission': 1230, 'demanding': 1231, 'run': 1232, 'gallons': 1233, 'drain': 1234, 'o': 1235, 'inhumane': 1236, 'prisoners': 1237, 'showing': 1238, 'padded': 1239, 'cell': 1240, 'extravagant': 1241, 'suicide': 1242, 'methods': 1243, '72nd': 1244, 'sitting': 1245, 'facets': 1246, '6': 1247, 'decisions': 1248, 'huge': 1249, 'exaggerated': 1250, 'unexplainable': 1251, 'happens': 1252, 'storywise': 1253, '30': 1254, 'motions': 1255, 'shakes': 1256, 'forwards': 1257, 'smooth': 1258, 'tracks': 1259, 'musics': 1260, 'appreciation': 1261, 'college': 1262, 'abandoned': 1263, 'traffic': 1264, 'lookie': 1265, 'loos': 1266, 'chalk': 1267, 'viewable': 1268, 'brutal': 1269, 'shoot': 1270, 'glitches': 1271, 'overlookable': 1272, 'caliber': 1273, 'jackie': 1274, 'gangster': 1275, 'sebastians': 1276, 'worn': 1277, 'cliché': 1278, 'relationships': 1279, 'drawn': 1280, 'deal': 1281, 'permission': 1282, 'rebellious': 1283, 'upper': 1284, 'judging': 1285, 'backflashes': 1286, 'solid': 1287, 'socially': 1288, 'critic': 1289, 'focusing': 1290, 'cool': 1291, 'moment': 1292, 'reflect': 1293, 'forcing': 1294, 'along': 1295, 'breath': 1296, 'naturally': 1297, 'evolve': 1298, 'glorify': 1299, 'abuse': 1300, 'incorrect': 1301, 'managing': 1302, 'ruin': 1303, 'portray': 1304, 'dictating': 1305, 'gone': 1306, 'opposite': 1307, 'wrote': 1308, 'suite': 1309, 'failed': 1310, 'badly': 1311, 'credit': 1312, 'media': 1313, 'maintain': 1314, 'summary': 1315, 'terminator': 1316, 'deprived': 1317, 'assuming': 1318, 'release': 1319, 'afi': 1320, 'dallas': 1321, 'remaining': 1322, 'insulting': 1323, 'goof': 1324, 'shots': 1325, 'breaks': 1326, \"let's\": 1327, 'indicator': 1328, 'details': 1329, 'disappointing': 1330, 'expecting': 1331, 'shut': 1332, 'nuff': 1333, 'filler': 1334, 'expand': 1335, 'sucks': 1336, 'moronic': 1337, 'deniz': 1338, \"akkaya's\": 1339, 'breasts': 1340, 'ruined': 1341, 'unneeded': 1342, 'garbage': 1343, 'rag': 1344, 'minimum': 1345, 'offal': 1346, 'compelled': 1347, 'create': 1348, 'discover': 1349, 'friggen': 1350, 'essay': 1351, 'reload': 1352, 'june': 1353, \"'08\": 1354, 'crappy': 1355, 'earn': 1356, 'sequel': 1357, 'killed': 1358, 'wee': 1359, 'hours': 1360, 'morning': 1361, 'battling': 1362, 'insomnia': 1363, 'drifting': 1364, 'missed': 1365, 'stronger': 1366, 'surprised': 1367, 'commenting': 1368, 'since': 1369, 'brooke': 1370, 'exceptional': 1371, 'nine': 1372, 'psychedelic': 1373, 'pulsating': 1374, 'symmetric': 1375, 'abstract': 1376, 'frame': 1377, 'start': 1378, 'birds': 1379, 'silhouetted': 1380, 'cup': 1381, 'tea': 1382, '8½': 1383, 'long': 1384, 'capsule': 1385, 'zero': 1386, 'chemistry': 1387, 'ingenious': 1388, 'uncomfortably': 1389, 'drifts': 1390, 'map': 1391, 'handle': 1392, 'molasses': 1393, 'swift': 1394, 'adjective': 1395, 'excruciating': 1396, 'pacing': 1397, 'intent': 1398, 'uplifting': 1399, 'curing': 1400, 'bummer': 1401, 'comprehensively': 1402, 'destructive': 1403, 'morale': 1404, 'clichés': 1405, 'entertained': 1406, 'mainstay': 1407, 'major': 1408, 'device': 1409, 'conflict': 1410, 'puts': 1411, 'waves': 1412, 'malicious': 1413, 'beings': 1414, 'pushes': 1415, \"someone's\": 1416, '90': 1417, 'conclusion': 1418, 'comforting': 1419, 'police': 1420, 'sirens': 1421, 'challenge': 1422, 'tired': 1423, 'hackneyed': 1424, 'formula': 1425, 'clever': 1426, 'personality': 1427, 'components': 1428, 'space': 1429, 'soul': 1430, 'trash': 1431, 'publicly': 1432, 'embarrassed': 1433, 'disservice': 1434, \"they've\": 1435, 'unfortuntately': 1436, 'harrowing': 1437, 'northern': 1438, 'area': 1439, 'grabbed': 1440, 'hold': 1441, 'heartstrings': 1442, 'refused': 1443, 'weeks': 1444, 'finished': 1445, 'tears': 1446, 'repulsion': 1447, 'shock': 1448, 'sympathy': 1449, 'misery': 1450, 'depressing': 1451, 'utterly': 1452, 'gripping': 1453, 'dear': 1454, 'showered': 1455, 'layer': 1456, 'sweet': 1457, 'icing': 1458, 'sugar': 1459, 'condensed': 1460, 'touched': 1461, 'discarded': 1462, 'mass': 1463, 'viewing': 1464, '7': 1465, 'practical': 1466, 'content': 1467, 'essence': 1468, 'gut': 1469, 'darkness': 1470, 'rain': 1471, 'broken': 1472, 'windows': 1473, 'cardboard': 1474, 'graphically': 1475, 'described': 1476, 'stench': 1477, 'poverty': 1478, 'replaced': 1479, 'sunshine': 1480, 'houses': 1481, 'twinkling': 1482, \"william's\": 1483, 'positivity': 1484, \"'reality'\": 1485, 'advise': 1486, 'hesitate': 1487, 'preparing': 1488, \"'schindler's\": 1489, \"list'\": 1490, 'tough': 1491, 'bear': 1492, 'roll': 1493, 'tought': 1494, \"'we\": 1495, 'turks': 1496, 'insult': 1497, 'heist': 1498, 'hostage': 1499, \"'\": 1500, 'checked': 1501, 'contrary': 1502, 'persuade': 1503, 'micheal': 1504, 'project': 1505, 'kept': 1506, 'raise': 1507, 'offer': 1508, 'supposedly': 1509, 'meditation': 1510, 'paid': 1511, 'answer': 1512, 'hiring': 1513, 'cheapest': 1514, 'equipment': 1515, 'difficulty': 1516, 'adjustin': 1517, 'vice': 1518, 'versa': 1519, 'anxious': 1520, 'meditate': 1521, 'outthere': 1522, 'affect': 1523, 'disbelief': 1524, 'fanciful': 1525, 'vincent': 1526, 'mad': 1527, 'magician': 1528, 'realizes': 1529, 'vocational': 1530, 'sold': 1531, 'devise': 1532, 'avenging': 1533, 'wronged': 1534, 'scheme': 1535, 'fire': 1536, 'below': 1537, 'compared': 1538, 'patrick': 1539, \"o'neal\": 1540, 'mary': 1541, 'murphy': 1542, 'eva': 1543, 'gabor': 1544, 'jay': 1545, 'novello': 1546, 'congratulate': 1547, 'genius': 1548, 'approved': 1549, 'mate': 1550, 'cost': 1551, 'intention': 1552, 'bucks': 1553, 'filming': 1554, 'supermarket': 1555, 'ones': 1556, 'jon': 1557, 'keeyes': 1558, 'purpose': 1559, 'angles': 1560, 'messed': 1561, \"they're\": 1562, 'toilet': 1563, 'paper': 1564, 'comes': 1565, 'apparent': 1566, 'serving': 1567, 'doubt': 1568, 'badass': 1569, 'shootout': 1570, \"should've\": 1571, 'oblivion': 1572, \"'till\": 1573, 'stress': 1574, 'goers': 1575, 'vote': 1576, 'unbelievably': 1577, 'wasteful': 1578, 'caricature': 1579, \"snail's\": 1580, 'photographed': 1581, 'advised': 1582, 'insufferably': 1583, 'preachy': 1584, 'plugs': 1585, 'cliche': 1586, 'swoozie': 1587, 'kurtz': 1588, 'requiring': 1589, 'worthless': 1590, 'readers': 1591, 'tape': 1592, \"who's\": 1593, 'outweigh': 1594, 'rarely': 1595, 'traumatic': 1596, 'shook': 1597, 'partially': 1598, 'revealed': 1599, 'flashbacks': 1600, 'spelled': 1601, 'until': 1602, 'claustrophobic': 1603, 'environment': 1604, 'causes': 1605, 'loose': 1606, 'extreme': 1607, 'possible': 1608, 'opportunity': 1609, 'strip': 1610, 'club': 1611, 'celebrate': 1612, 'soon': 1613, 'follows': 1614, 'strippers': 1615, 'beach': 1616, 'party': 1617, 'befriends': 1618, 'pulls': 1619, 'dealing': 1620, 'underworld': 1621, 'technically': 1622, 'suffers': 1623, 'lackluster': 1624, 'engaging': 1625, 'counting': 1626, 'freeze': 1627, 'frames': 1628, 'echos': 1629, 'normally': 1630, 'utilize': 1631, \"character's\": 1632, 'sporadically': 1633, 'tossed': 1634, 'attempt': 1635, 'unknowns': 1636, 'notably': 1637, 'antagonist': 1638, 'suspect': 1639, 'projects': 1640, 'mentioning': 1641, 'rating': 1642, 'hotness': 1643, '11': 1644, 'distract': 1645, 'sit': 1646, 'semi': 1647, 'fictionalizing': 1648, 'screw': 1649, 'ups': 1650, 'incredulous': 1651, 'fantasies': 1652, 'rap': 1653, 'acted': 1654, 'stereotypical': 1655, 'lists': 1656, '2007': 1657, '2008': 1658, 'showtime': 1659, 'listed': 1660, 'synopsis': 1661, 'halfway': 1662, 'realized': 1663, 'undercover': 1664, 'cop': 1665, 'tho': 1666, 'stereotype': 1667, 'prior': 1668, 'suspicious': 1669, 'appearing': 1670, 'freebie': 1671, 'blonde': 1672, 'taken': 1673, 'flood': 1674, 'non': 1675, 'sounds': 1676, 'deserves': 1677, 'b': 1678, 'grade': 1679, 'slop': 1680, 'spoken': 1681, 'realistic': 1682, 'representation': 1683, 'subsequent': 1684, 'spiral': 1685, 'perpetuation': 1686, 'state': 1687, 'events': 1688, 'mentioned': 1689, 'overused': 1690, 'unconvincing': 1691, 'irrelevant': 1692, 'concerned': 1693, 'lacklustre': 1694, 'unimaginative': 1695, 'implausible': 1696, 'reports': 1697, 'granted': 1698, 'confronted': 1699, 'carry': 1700, 'intermittent': 1701, 'punches': 1702, 'towards': 1703, 'revel': 1704, 'furthermore': 1705, 'educational': 1706, 'scare': 1707, 'number': 1708, 'board': 1709, 'effective': 1710, \"'requiem\": 1711, \"dream'\": 1712, \"'trainspotting'\": 1713, \"'fear\": 1714, 'loathing': 1715, 'las': 1716, \"vegas'\": 1717, \"'candy'\": 1718, 'examples': 1719, 'lighthearted': 1720, \"'go'\": 1721, \"'halfbaked'\": 1722, 'stolen': 1723, \"'lock\": 1724, 'stock': 1725, 'smokling': 1726, \"barrels'\": 1727, 'tainted': 1728, \"'loaded'\": 1729, 'strongly': 1730, 'suggest': 1731, 'offense': 1732, 'test': 1733, 'demanded': 1734, 'next': 1735, 'bought': 1736, 'sink': 1737, 'act': 1738, 'ass': 1739, 'allow': 1740, 'noise': 1741, 'paint': 1742, 'skirmish': 1743, 'game': 1744, 'bloke': 1745, 'robbery': 1746, 'gang': 1747, 'whining': 1748, 'voice': 1749, 'k': 1750, 'seconds': 1751, 'whoo': 1752, 'hoo': 1753, 'dumb': 1754, 'bounce': 1755, 'dumbest': 1756, 'rips': 1757, 'manages': 1758, 'afterthought': 1759, 'cant': 1760, 'nonsense': 1761, 'somebody': 1762, 'somewhere': 1763, \"'oh\": 1764, 'load': 1765, \"shite'\": 1766, 'call': 1767, 'downloading': 1768, 'illegally': 1769, 'trailer': 1770, 'download': 1771, 'painful': 1772, 'finishing': 1773, 'wishes': 1774, 'refund': 1775, 'spent': 1776, '15': 1777, 'laced': 1778, 'controlled': 1779, 'complete': 1780, 'spinelessness': 1781, 'irresponsibility': 1782, 'rapid': 1783, 'privilege': 1784, 'culture': 1785, 'allows': 1786, 'seduced': 1787, 'mind': 1788, 'altering': 1789, 'understandable': 1790, 'observing': 1791, 'penny': 1792, 'pound': 1793, 'dedication': 1794, 'met': 1795, 'impossible': 1796, 'frankly': 1797, 'besides': 1798, 'stare': 1799, 'monica': 1800, 'keena': 1801, 'qualities': 1802, 'national': 1803, 'preservation': 1804, 'foundation': 1805, 'regardless': 1806, 'exact': 1807, 'indicative': 1808, 'pop': 1809, 'stylings': 1810, '60s': 1811, 'consists': 1812, 'simple': 1813, 'absolutely': 1814, 'intended': 1815, 'tiresome': 1816, 'bluntly': 1817, 'appeal': 1818, 'hip': 1819, 'understood': 1820, 'mortals': 1821, 'basically': 1822, 'skimmed': 1823, 'spots': 1824, 'crawford': 1825, 'threw': 1826, 'cuss': 1827, 'sentence': 1828, 'saying': 1829, 'cussing': 1830, 'flashy': 1831, 'shaking': 1832, 'headache': 1833, 'dramatic': 1834, 'lol': 1835, 'anyways': 1836, 'die': 1837, 'yeah': 1838, 'lars': 1839, \"trier's\": 1840, \"'breaking\": 1841, \"waves'\": 1842, \"'dancer\": 1843, \"night'\": 1844, 'admired': 1845, \"'dogville'\": 1846, 'dry': 1847, \"'europa'\": 1848, 'succeeded': 1849, 'success': 1850, 'european': 1851, 'oscar': 1852, 'foreign': 1853, 'explicit': 1854, 'extrovert': 1855, 'ambiguity': 1856, 'escape': 1857, 'treating': 1858, 'followed': 1859, 'victors': 1860, 'executioners': 1861, 'sides': 1862, 'survival': 1863, 'aftermath': 1864, 'catastrophic': 1865, 'nations': 1866, 'individuals': 1867, 'forever': 1868, 'disputes': 1869, 'courageous': 1870, 'decades': 1871, 'expression': 1872, 'fit': 1873, 'task': 1874, 'include': 1875, 'quotes': 1876, 'descending': 1877, 'directly': 1878, 'pre': 1879, 'brave': 1880, 'evil': 1881, 'crossing': 1882, 'speed': 1883, 'continent': 1884, 'dark': 1885, 'dramatism': 1886, 'sparkles': 1887, 're': 1888, 'birth': 1889, 'obsession': 1890, 'order': 1891, 'regulation': 1892, 'punctuality': 1893, 'civility': 1894, 'populate': 1895, 'spy': 1896, 'origin': 1897, 'coming': 1898, 'process': 1899, 'reconciliation': 1900, 'finds': 1901, 'corruption': 1902, 'liberators': 1903, 'oppressive': 1904, 'occupiers': 1905, 'resigned': 1906, 'fate': 1907, 'continue': 1908, 'doubtfully': 1909, 'treason': 1910, 'treatment': 1911, 'betrays': 1912, 'leopold': 1913, 'kessler': 1914, 'played': 1915, 'jean': 1916, 'marc': 1917, 'barr': 1918, 'confused': 1919, 'credibility': 1920, 'imitation': 1921, '30s': 1922, 'usage': 1923, 'color': 1924, 'majority': 1925, 'trier': 1926, 'artistic': 1927, 'filmmaker': 1928, 'planning': 1929, 'suffice': 1930, 'studying': 1931, 'horrendous': 1932, 'throughout': 1933, 'speaks': 1934, 'jog': 1935, 'fair': 1936, 'focuses': 1937, 'finding': 1938, 'screenplay': 1939, 'fans': 1940, 'coartship': 1941, 'wiser': 1942, 'cautious': 1943, 'matter': 1944, 'tremendously': 1945, 'admire': 1946, 'delicate': 1947, 'gold': 1948, 'elderly': 1949, 'break': 1950, 'cinematic': 1951, 'bette': 1952, 'anywhere': 1953, 'whistling': 1954, 'song': 1955, 'musicals': 1956, 'stuck': 1957, 'costumes': 1958, 'lavish': 1959, 'surprising': 1960, 'catlike': 1961, 'costume': 1962, 'transformed': 1963, \"connery's\": 1964, 'cute': 1965, 'bold': 1966, 'princess': 1967, 'feature': 1968, 'length': 1969, 'personalities': 1970, 'favourite': 1971, 'pretend': 1972, 'drowning': 1973, 'country': 1974, 'rage': 1975, 'table': 1976, 'pretending': 1977, 'parents': 1978, 'alike': 1979, \"here's\": 1980, 'evidence': 1981, 'worship': 1982, 'acknowledge': 1983, 'wholesome': 1984, 'plotting': 1985, 'values': 1986, 'enchanting': 1987, 'inventively': 1988, 'sequences': 1989, 'golden': 1990, 'belongs': 1991, 'introduce': 1992, 'gloved': 1993, 'sexually': 1994, 'frustrated': 1995, 'blends': 1996, 'fashioned': 1997, 'myth': 1998, 'murderous': 1999, 'constantly': 2000, 'siblings': 2001, '100': 2002, '6th': 2003, 'inevitable': 2004, 'choreographer': 2005, 'prominent': 2006, 'modeling': 2007, 'agency': 2008, 'sharing': 2009, 'bed': 2010, 'manager': 2011, 'spree': 2012, 'obvious': 2013, 'culprit': 2014, 'states': 2015, 'fascinating': 2016, 'history': 2017, 'wears': 2018, 'blood': 2019, 'cloak': 2020, 'produces': 2021, 'ghastly': 2022, 'whenever': 2023, 'exactly': 2024, 'gentle': 2025, 'barbarically': 2026, 'stabbed': 2027, 'dagger': 2028, 'dragged': 2029, 'cars': 2030, 'impaled': 2031, 'fences': 2032, 'latter': 2033, 'acts': 2034, 'request': 2035, 'classy': 2036, 'tasteful': 2037, 'influence': 2038, 'forgotten': 2039, 'till': 2040, 'received': 2041, 'reception': 2042, 'commentators': 2043, 'coplandesque': 2044, 'americana': 2045, 'discovered': 2046, 'none': 2047, 'poignant': 2048, \"schindler's\": 2049, 'list': 2050, 'associates': 2051, 'bombasticities': 2052, 'wars': 2053, 'surpasses': 2054, 'sensitivity': 2055, 'fully': 2056, 'keeping': 2057, 'tender': 2058, 'wit': 2059, 'sophistication': 2060, 'education': 2061, 'green': 2062, 'valley': 2063, 'konrack': 2064, 'voigt': 2065, 'african': 2066, 'charges': 2067, 'carolina': 2068, 'danny': 2069, \"devito's\": 2070, 'renaissance': 2071, 'intellectual': 2072, 'spiritual': 2073, 'awakening': 2074, 'told': 2075, 'addition': 2076, 'owes': 2077, 'la': 2078, 'dama': 2079, 'rossa': 2080, 'uccide': 2081, 'sette': 2082, 'volte': 2083, 'aka': 2084, 'genres': 2085, 'surpassed': 2086, 'hopes': 2087, '1971': 2088, 'atmospheric': 2089, 'compare': 2090, 'instant': 2091, 'hands': 2092, 'lover': 2093, 'missing': 2094, 'delivers': 2095, 'inventive': 2096, 'suspense': 2097, 'sublimely': 2098, 'eerily': 2099, 'combinations': 2100, 'terror': 2101, 'wildenbrück': 2102, 'legend': 2103, 'hundred': 2104, 'kill': 2105, 'photographer': 2106, 'murdered': 2107, 'proved': 2108, 'colorful': 2109, 'creepiness': 2110, 'effectively': 2111, 'feast': 2112, 'visually': 2113, \"grandfather's\": 2114, 'capable': 2115, 'goosebumps': 2116, 'arguably': 2117, 'appreciated': 2118, 'prime': 2119, 'ladies': 2120, \"bouchet's\": 2121, 'presence': 2122, 'graded': 2123, 'appearances': 2124, 'starred': 2125, 'cult': 2126, 'within': 2127, 'fernando': 2128, 'di': 2129, \"leo's\": 2130, 'milano': 2131, 'calibro': 2132, '9': 2133, 'lucio': 2134, \"fulci's\": 2135, 'highlight': 2136, 'duckling': 2137, 'unforgettable': 2138, 'wonderful': 2139, 'miss': 2140, 'marina': 2141, 'malfatti': 2142, 'beauties': 2143, 'bare': 2144, \"nicolai's\": 2145, 'intensely': 2146, 'eerie': 2147, 'ingeniously': 2148, 'tension': 2149, 'increses': 2150, 'passing': 2151, 'minute': 2152, 'stunning': 2153, 'words': 2154, 'easily': 2155, 'ranks': 2156, 'finest': 2157, 'priority': 2158, 'appeared': 2159, 'blank': 2160, 'fill': 2161, 'themselves': 2162, 'nor': 2163, 'smacked': 2164, 'supporter': 2165, 'live': 2166, 'relatives': 2167, 'quarrels': 2168, 'troubled': 2169, 'knocked': 2170, 'typically': 2171, 'jackass': 2172, 'nest': 2173, 'egg': 2174, 'buys': 2175, 'thumbs': 2176, \"miraglio's\": 2177, 'mixing': 2178, 'requisite': 2179, 'sinister': 2180, 'stew': 2181, 'paramount': 2182, 'twisty': 2183, 'field': 2184, 'series': 2185, 'seeming': 2186, 'fulfillment': 2187, 'ancient': 2188, 'prophecy': 2189, 'murderer': 2190, 'cloaked': 2191, 'madwoman': 2192, 'assortment': 2193, 'headed': 2194, 'ridiculously': 2195, 'lustful': 2196, 'tramp': 2197, \"barbara's\": 2198, 'ingredient': 2199, 'superior': 2200, 'catchy': 2201, 'hummable': 2202, 'nicolai': 2203, 'provides': 2204, 'scenery': 2205, 'largely': 2206, 'wurzburg': 2207, 'treat': 2208, 'pleased': 2209, 'report': 2210, 'satisfied': 2211, 'various': 2212, 'knifings': 2213, 'shootings': 2214, 'impalements': 2215, 'carnage': 2216, 'tastefully': 2217, 'dishes': 2218, 'crypts': 2219, 'freaky': 2220, 'rats': 2221, 'bats': 2222, \"'em\": 2223, 'obligatory': 2224, 'ugo': 2225, 'pagliai': 2226, 'hunky': 2227, 'folks': 2228, 'print': 2229, 'loads': 2230, 'extras': 2231, 'boot': 2232, 'thanks': 2233, 'short': 2234, 'expertly': 2235, 'scripted': 2236, 'perfectly': 2237, 'searing': 2238, 'parody': 2239, 'london': 2240, 'rolling': 2241, 'vulgar': 2242, 'provocative': 2243, 'witty': 2244, 'sharp': 2245, 'superbly': 2246, 'caricatured': 2247, 'cross': 2248, 'section': 2249, 'accurate': 2250, 'following': 2251, 'escapades': 2252, 'term': 2253, 'parodying': 2254, 'correctness': 2255, 'flies': 2256, 'poke': 2257, 'taboo': 2258, 'disappoint': 2259, 'marvelous': 2260, 'singer': 2261, 'demonstrates': 2262, 'acrobatic': 2263, 'cartwheel': 2264, 'starring': 2265, 'connery': 2266, 'likable': 2267, 'futz': 2268, 'experimental': 2269, 'movement': 2270, 'york': 2271, '1960s': 2272, 'origins': 2273, 'darkly': 2274, 'liberty': 2275, 'morality': 2276, 'relevant': 2277, 'congress': 2278, 'outlaw': 2279, 'trashing': 2280, 'constitution': 2281, 'norms': 2282, 'removed': 2283, 'hate': 2284, 'surface': 2285, 'fable': 2286, 'animals': 2287, 'stifling': 2288, 'conformity': 2289, 'won': 2290, 'acclaim': 2291, 'toured': 2292, 's': 2293, 'influenced': 2294, 'luckily': 2295, 'originally': 2296, 'conceived': 2297, 'tom': 2298, \"o'horgan\": 2299, 'directed': 2300, 'jesus': 2301, 'superstar': 2302, 'aggressive': 2303, 'unsettling': 2304, 'glorious': 2305, 'wildly': 2306, 'imaginative': 2307, 'storytelling': 2308, 'underneath': 2309, 'humorous': 2310, 'surprisingly': 2311, 'trademark': 2312, 'works': 2313, 'sly': 2314, 'particular': 2315, 'dunce': 2316, 'supposed': 2317, 'eighties': 2318, 'overly': 2319, 'computer': 2320, 'generated': 2321, 'fare': 2322, 'pieces': 2323, 'sung': 2324, 'marner': 2325, 'particularly': 2326, 'fourth': 2327, 'nobles': 2328, 'sing': 2329, 'battle': 2330, 'rights': 2331, 'known': 2332, \"freakin'\": 2333, 'sings': 2334, 'dances': 2335, 'fits': 2336, 'devious': 2337, 'mischievous': 2338, 'trouble': 2339, 'eight': 2340, 'advance': 2341, \"you've\": 2342, 'villainous': 2343, 'dust': 2344, 'trap': 2345, 'enjoys': 2346, \"'stanley\": 2347, 'triumph': 2348, 'spirit': 2349, 'struggle': 2350, 'literate': 2351, 'realize': 2352, 'starting': 2353, 'stopping': 2354, 'nicely': 2355, 'view': 2356, 'credible': 2357, 'reviewers': 2358, 'rendered': 2359, 'consistent': 2360, 'carefully': 2361, 'chosen': 2362, 'add': 2363, 'depth': 2364, 'meaning': 2365, 'romantic': 2366, 'martin': 2367, 'ritt': 2368, 'pleasure': 2369, 'due': 2370, 'charisma': 2371, 'closet': 2372, 'inventor': 2373, 'rest': 2374, 'laid': 2375, 'verges': 2376, 'bland': 2377, 'pleasant': 2378, 'rosy': 2379, 'hued': 2380, 'fantasy': 2381, 'overtures': 2382, 'tool': 2383, 'ensuing': 2384, 'fireworks': 2385, 'intentionally': 2386, 'colorless': 2387, 'leads': 2388, 'toned': 2389, 'finale': 2390, 'fluff': 2391, 'cynics': 2392, 'deserve': 2393, 'satisfying': 2394, \"world's\": 2395, 'stopped': 2396, 'pit': 2397, 'door': 2398, 'participants': 2399, 'including': 2400, 'grand': 2401, 'experiment': 2402, 'hey': 2403, 'active': 2404, 'listened': 2405, 'comments': 2406, 'tomreynolds2004': 2407, 'evident': 2408, 'travel': 2409, 'darker': 2410, 'roads': 2411, 'loneliness': 2412, 'disappointment': 2413, 'sorrow': 2414, 'portrayed': 2415, 'plenty': 2416, 'bitter': 2417, 'angry': 2418, 'comfort': 2419, 'quagmire': 2420, 'sentimental': 2421, 'sappy': 2422, 'became': 2423, 'humanity': 2424, 'dislike': 2425, 'vietnam': 2426, 'intelligence': 2427, 'goodness': 2428, 'fail': 2429, 'abilities': 2430, 'toughness': 2431, 'sell': 2432, 'viewed': 2433, 'premise': 2434, 'authentic': 2435, 'ct': 2436, 'collectors': 2437, 'item': 2438, 'passable': 2439, 'satisfy': 2440, 'grownups': 2441, 'hide': 2442, 'braininess': 2443, 'doctorate': 2444, 'yale': 2445, \"diniro's\": 2446, 'guy': 2447, 'loser': 2448, 'turns': 2449, \"jane's\": 2450, '1990': 2451, 'henry': 2452, 'ford': 2453, 'thomas': 2454, 'edison': 2455, 'handled': 2456, \"nobody's\": 2457, 'fool': 2458, 'mid': 2459, '90s': 2460, \"year's\": 2461, '2003': 2462, 'schmidt': 2463, 'stream': 2464, 'studios': 2465, 'adolescents': 2466, 'reserve': 2467, 'screens': 2468, 'multi': 2469, 'complexes': 2470, 'fluid': 2471, 'seamless': 2472, 'skip': 2473, 'places': 2474, 'library': 2475, 'minor': 2476, 'detract': 2477, 'impact': 2478, 'incomprehensible': 2479, 'hardest': 2480, 'fix': 2481, 'smart': 2482, 'function': 2483, 'childhood': 2484, 'educated': 2485, \"hasn't\": 2486, 'faults': 2487, 'strengths': 2488, 'compliment': 2489, 'stretch': 2490, 'wind': 2491, 'hid': 2492, 'construction': 2493, 'mysteries': 2494, 'explained': 2495, 'unfolding': 2496, 'assume': 2497, 'rethink': 2498, 'movie\\x97just': 2499, 'explores': 2500, 'taylorist': 2501, 'modes': 2502, 'capitalist': 2503, 'treated': 2504, 'cogs': 2505, 'machine': 2506, 'overseen': 2507, 'managers': 2508, 'wielding': 2509, 'clipboards': 2510, 'controlling': 2511, 'exposed': 2512, 'firing': 2513, 'meet': 2514, 'criteria': 2515, 'supervisor': 2516, 'unspecified': 2517, 'mistake': 2518, 'destroys': 2519, 'families': 2520, 'send': 2521, 'nursing': 2522, 'dies': 2523, 'teen': 2524, 'mother': 2525, 'plant': 2526, 'declining': 2527, 'wages': 2528, 'partners': 2529, 'implication': 2530, 'nobody': 2531, 'illness': 2532, 'multiple': 2533, 'medical': 2534, 'lived': 2535, 'costly': 2536, 'unsuccessful': 2537, 'unemployment': 2538, 'office': 2539, 'yells': 2540, 'savings': 2541, 'lift': 2542, 'stake': 2543, 'bourgeois': 2544, 'notions': 2545, 'perfection': 2546, 'buy': 2547, 'reference': 2548, 'race': 2549, 'jail': 2550, 'men': 2551, 'suffer': 2552, 'disproportionally': 2553, 'incarceration': 2554, 'rates': 2555, 'remarks': 2556, 'composed': 2557, 'prisoner': 2558, 'wage': 2559, 'slave': 2560, 'believes': 2561, 'spite': 2562, \"father's\": 2563, 'traveling': 2564, 'salesman': 2565, 'reduced': 2566, 'purely': 2567, 'instrumental': 2568, 'contract': 2569, 'suggesting': 2570, 'married': 2571, 'wrong': 2572, 'eat': 2573, 'routine': 2574, 'artisanal': 2575, 'ideal': 2576, 'modernists': 2577, \"1920's\": 2578, 'socialists': 2579, 'provide': 2580, 'basic': 2581, 'allowing': 2582, 'fuller': 2583, 'traditional': 2584, 'gender': 2585, 'cooks': 2586, 'cleans': 2587, 'iron': 2588, 'mains': 2589, 'income': 2590, 'extended': 2591, 'brings': 2592, 'limits': 2593, 'gendered': 2594, 'metaphor': 2595, 'masculine': 2596, 'systems': 2597, 'circulation': 2598, 'cultural': 2599, 'enable': 2600, 'feminized': 2601, 'jobs': 2602, 'cooking': 2603, 'cleaning': 2604, 'excluded': 2605, 'regular': 2606, 'circulations': 2607, 'participate': 2608, 'bank': 2609, \"driver's\": 2610, 'license': 2611, 'ride': 2612, 'bus': 2613, 'asks': 2614, 'exists': 2615, 'learning': 2616, 'grabs': 2617, 'auto': 2618, 'repair': 2619, 'farming': 2620, 'spirituality': 2621, 'relativized': 2622, 'placed': 2623, 'value': 2624, 'plane': 2625, 'organized': 2626, 'religion': 2627, 'occasionally': 2628, 'dresser': 2629, 'pans': 2630, 'acknowledged': 2631, 'moral': 2632, 'force': 2633, 'devoted': 2634, 'mentions': 2635, 'rosary': 2636, 'objects': 2637, 'purse': 2638, 'snatching': 2639, 'enters': 2640, 'lands': 2641, 'managerial': 2642, 'position': 2643, 'health': 2644, 'car': 2645, 'taking': 2646, 'head': 2647, 'breadwinner': 2648, 'designer': 2649, 'dreaming': 2650, 'products': 2651, 'enduring': 2652, 'drudgery': 2653, 'incongruous': 2654, 'forced': 2655, 'exec': 2656, 'worried': 2657, 'according': 2658, 'pundits': 2659, \"we've\": 2660, 'comfortably': 2661, 'slightly': 2662, 'nostalgic': 2663, 'historical': 2664, 'distance': 2665, 'analyze': 2666, 'during': 2667, 'nevertheless': 2668, 'brain': 2669, 'disregard': 2670, 'close': 2671, \"women's\": 2672, 'usual': 2673, 'visuals': 2674, 'photography': 2675, 'casting': 2676, 'winner': 2677, 'fresh': 2678, 'curious': 2679, 'fx': 2680, 'entranced': 2681, 'held': 2682, 'amusing': 2683, 'disney': 2684, 'saccharine': 2685, 'sweetness': 2686, 'scary': 2687, 'benign': 2688, 'interestingly': 2689, 'implausibility': 2690, 'staying': 2691, 'cartoon': 2692, 'ran': 2693, 'programs': 2694, '35': 2695, 'profession': 2696, \"high's\": 2697, 'satire': 2698, 'closer': 2699, 'scramble': 2700, 'financially': 2701, 'pathetic': 2702, \"teachers'\": 2703, 'pomp': 2704, 'pettiness': 2705, 'remind': 2706, 'schools': 2707, 'knew': 2708, 'repeatedly': 2709, 'burn': 2710, 'recalled': 2711, 'inspector': 2712, 'sack': 2713, 'welcome': 2714, 'pity': 2715, 'porno': 2716, 'cartoons': 2717, 'park': 2718, 'similar': 2719, 'format': 2720, 'adventures': 2721, 'exploding': 2722, 'sweets': 2723, 'behaved': 2724, 'bitches': 2725, 'leader': 2726, 'idiotic': 2727, 'bip': 2728, 'maths': 2729, 'teacher': 2730, 'fantastic': 2731, 'lenny': 2732, \"henry's\": 2733, 'gina': 2734, 'yashere': 2735, 'eastenders': 2736, 'chrissie': 2737, 'watts': 2738, 'tracy': 2739, 'ann': 2740, 'oberman': 2741, 'smack': 2742, \"pony's\": 2743, 'doon': 2744, 'mackichan': 2745, \"ringers'\": 2746, 'perry': 2747, \"blunder's\": 2748, 'nina': 2749, 'conti': 2750, 'canada': 2751, 'hall': 2752, 'fame': 2753, 'sleeping': 2754, 'normal': 2755, 'rougher': 2756, 'learn': 2757, 'involves': 2758, 'honest': 2759, 'fairly': 2760, 'mild': 2761, 'important': 2762, 'stresses': 2763, 'modern': 2764, 'devastating': 2765, 'career': 2766, 'consequences': 2767, 'vital': 2768, 'revolves': 2769, 'acquainted': 2770, 'fellow': 2771, 'employee': 2772, 'cafeteria': 2773, 'discovers': 2774, 'lessons': 2775, 'predict': 2776, 'initially': 2777, 'wary': 2778, 'involvement': 2779, 'develop': 2780, 'competently': 2781, 'coping': 2782, 'prospects': 2783, 'pregnant': 2784, 'unemployed': 2785, 'endearing': 2786, 'resourceful': 2787, 'bringing': 2788, 'dignity': 2789, 'commands': 2790, 'charming': 2791, 'yuppie': 2792, 'depicted': 2793, 'romances': 2794, 'aged': 2795, 'pair': 2796, 'struggles': 2797, 'heartwarming': 2798, 'troubling': 2799, 'albeit': 2800, 'fictional': 2801, 'rang': 2802, 'gulp': 2803, 'sudden': 2804, 'emotion': 2805, 'smile': 2806, 'sheer': 2807, 'identification': 2808, 'rank': 2809, 'martha': 2810, 'rewarding': 2811, 'warming': 2812, 'overcome': 2813, \"stanley's\": 2814, 'learned': 2815, 'widower': 2816, 'bakery': 2817, 'meets': 2818, 'decides': 2819, 'teach': 2820, 'romantically': 2821, 'learns': 2822, 'chicago': 2823, 'marry': 2824, 'profanity': 2825, 'rare': 2826, \"today's\": 2827, 'round': 2828}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwUE6-BlOAFi"
      },
      "source": [
        "###################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEySNAEKPd2W",
        "outputId": "6c38d0df-e66b-4b5f-dfa0-5f2eb4e9a2b5"
      },
      "source": [
        "#Data Sequencing\n",
        "\n",
        "#문자를 숫자로 변환하는 작업을 수행한다\n",
        "#각 문장에서 상위 빈도 9,999(max_words)개의 단어만 추출하여 word_index의 숫자를 가지는 리스트로 변환한다.\n",
        "data = tokenizer.texts_to_sequences(texts)  #빈도 10,000의 Tokenizer 결과가 여기서 반영된다\n",
        "\n",
        "print('data 0:', data[0])\n",
        "# 각 단어들이 숫자 형태의 리스트로 변형되었다\n",
        "# texts의 첫 번째 행의 단어들이 숫자로 변한 모습을 보여준다\n",
        "# 상위 빈도 10,000에 속하는 것들이므로 숫자의 범위가 1~9999이다\n",
        "# 빈도 9,999 내에 속하지 않는 단어들은 버려진다\n",
        "print('text 0:', texts[0])#texts[0]의 본래의 단어들"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data 0: [43, 4, 3, 179, 40, 34, 1140, 308, 13, 3, 686, 494, 46, 17, 3, 1141, 142, 12, 7, 3, 687, 384, 4, 688, 495, 3, 1142, 689, 496, 7, 690, 90, 29, 691, 1143, 1144, 41, 1, 692, 1145, 4, 49, 1146, 309, 11, 693, 688, 1, 180, 47, 17, 52, 385, 1147, 1148, 254, 11, 37, 68, 181, 1149, 39, 216, 45, 1, 694, 106, 26, 690, 181, 1, 1150, 1151, 69, 80, 1152, 310, 695, 5, 3, 1153, 1154, 25, 3, 1155, 311, 49, 143, 144, 21, 255, 115, 17, 36, 33, 497, 41, 312, 62, 1156, 1157, 312, 386, 1158, 1159, 2, 1160, 1161, 77, 26, 123, 1162]\n",
            "text 0: Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EyjpkyPQ4T5",
        "outputId": "24bbb54e-d606-4695-d19b-67c3acf1ef53"
      },
      "source": [
        "#타입확인\n",
        "\n",
        "#현재의 texts와 data의 타입은 list\n",
        "print(type(texts))\n",
        "print(type(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXCO_8WwRMWu",
        "outputId": "65aebd1f-a386-45ff-aaa3-0bb6141df4d7"
      },
      "source": [
        "#Data Padding 연습\n",
        "#Padding은 데이터의 길이를 고정시켜준다\n",
        "#지정된 길이에 모자라는 것은 0으로 채우고, 넘치는 것은 잘라낸다\n",
        "#넘치는 것을 잘라내는 이유는 문자잉 길어질수록 많은 종류의 단어가 나오기때문\n",
        "#또한, 길이를 고정해야 텐서의 크기가 맞춰진다\n",
        "#기본값으로 단어의 선택은 뒤에서부터 한다.\n",
        "#또한 nested list를 2D 텐서(2차원 넘파이 배열)로 만든다\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "sequences = [[1, 2, 3, 4, 5], [1, 2, 3, 4], [1]]\n",
        "padded = pad_sequences(sequences, maxlen=3)\n",
        "print(padded)\n",
        "#maxlen = 3 으로 하였으므로,\n",
        "#첫 번째 내부 리스트는 3,4,5 두번째 내부 리스트는 2,3,4가 선택되었다\n",
        "#세번째 내부 리스트는 길이가 모자라므로 앞에서부터 0으로 채웠다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 4 5]\n",
            " [2 3 4]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUz-kExGSEbG",
        "outputId": "d97eed64-95bc-48c7-b445-9c42c6ebde72"
      },
      "source": [
        "data = pad_sequences(data, maxlen=maxlen)\n",
        "print('data=',data)\n",
        "print('data0=', data[0])\n",
        "print(len(data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data= [[   0    0    0 ...   26  123 1162]\n",
            " [   0    0    0 ...  501   71  200]\n",
            " [ 187  150    6 ...  725  723  268]\n",
            " ...\n",
            " [ 118 2767   13 ...    3 2801   88]\n",
            " [   0    0    0 ...    2 2811  443]\n",
            " [   0    0    0 ... 2828    6    6]]\n",
            "data0= [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0   43    4    3  179   40   34 1140  308   13    3\n",
            "  686  494   46   17    3 1141  142   12    7    3  687  384    4  688\n",
            "  495    3 1142  689  496    7  690   90   29  691 1143 1144   41    1\n",
            "  692 1145    4   49 1146  309   11  693  688    1  180   47   17   52\n",
            "  385 1147 1148  254   11   37   68  181 1149   39  216   45    1  694\n",
            "  106   26  690  181    1 1150 1151   69   80 1152  310  695    5    3\n",
            " 1153 1154   25    3 1155  311   49  143  144   21  255  115   17   36\n",
            "   33  497   41  312   62 1156 1157  312  386 1158 1159    2 1160 1161\n",
            "   77   26  123 1162]\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGtSVOLPSluJ",
        "outputId": "7ba07f6e-6cea-4d7a-c5f5-656353a6e97b"
      },
      "source": [
        "#타입  확인\n",
        "#Padding을 거치게 되면 Numpy 배열로 바뀌고, shape를 갖는다(2D tensor)\n",
        "\n",
        "print(type(texts))\n",
        "print(type(data))\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "(60, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc6O14QwUFBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da614ce-bae0-4aad-e8c8-1e0fe54169cf"
      },
      "source": [
        "#One-Hot Encoding 연습\n",
        "\n",
        "#One-hot enccoding은 모든 숫자를 0과 1로 만든다\n",
        "#그렇지 않으면 index값이 특성의 크기로 간주한다\n",
        "\n",
        "sample = [[5,6,7], [8,9,10]]\n",
        "arr = np.zeros((len(sample), 10+1))# '10'은 11번째에 들어가게  되므로 11개의공간을 만든다(패딩0고려)\n",
        "\n",
        "for i, seq in enumerate(sample):    #리스트가 2개이므로 i는 총 2회(0, 1)반복되며,\n",
        "    arr[i,seq] = 1. #각 i에서 리스트의 number가 가리키는 곳에 1을 기록한다\n",
        "\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "IN_mpfpC4GHy",
        "outputId": "f97a8f07-6d80-4554-a21f-a166dac8f450"
      },
      "source": [
        "# 원-핫 인코딩 함수\n",
        "def to_one_hot(sequences, dimension):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# data를 one-hot-encoding으로 0과 1의 벡터로 변환\n",
        "# label은 이미 0과 1로 태깅되어 있으므로, list에서 넘파이 배열로만 변환. float32를 지정하지 않으면 int32로 저장된다\n",
        "data=  to_one_hot(data, dimension=max_words) \n",
        "labels = np.asarray(labels).astype('float32') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-67d27a4d9d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# data를 one-hot-encoding으로 0과 1의 벡터로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# label은 이미 0과 1로 태깅되어 있으므로, list에서 넘파이 배열로만 변환. float32를 지정하지 않으면 int32로 저장된다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-67d27a4d9d66>\u001b[0m in \u001b[0;36mto_one_hot\u001b[0;34m(sequences, dimension)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cupJ0Ap7CA1",
        "outputId": "730614f0-5c0f-4def-9a20-03de6ba18bb4"
      },
      "source": [
        "#One-Hot Encoding 결과 확인\n",
        "print('data:', data)\n",
        "print(len(data[0])) # dimension=10000으로 했으므로 각 행은 10,000개를 가지고 있다\n",
        "print('data [0][0:100]:', data[0][0:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data: [[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "10000\n",
            "data [0][0:100]: [0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ01WMVa70RS",
        "outputId": "fdfc7963-e9cb-4732-8b03-4d18d4bc12ab"
      },
      "source": [
        "#타입확인\n",
        "# One-Hot Encoding을 거치게 되면 타입은 그대로이나 shape가 바뀐다\n",
        "print(type(texts)) # list\n",
        "print(type(data)) # numpy.ndarray\n",
        "print(data.shape) # (25000, 10000) small 데이터는 (60, 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "(60, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-MOF5Ch8TcT",
        "outputId": "632425d0-8b53-40c5-ef75-2a3813926fcd"
      },
      "source": [
        "#Train 데이터와 Validation 데이터 준비\n",
        "print('데이터 텐서의 크기:', data.shape) # (25000, 10000)\n",
        "print('레이블 텐서의 크기:', labels.shape) # (25000,) \n",
        "indices = np.arange(data.shape[0]) # 0 ~ 24999 까지의 숫자를 생성\n",
        "np.random.shuffle(indices) # 0 ~ 24999 까지의 숫자를 랜덤하게 섞음\n",
        "data = data[indices] # 이것을 인덱스로 하여 2D 텐서 데이터를 섞음\n",
        "labels = labels[indices] # label도 같은 순서로 섞음\n",
        "print(indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 텐서의 크기: (60, 10000)\n",
            "레이블 텐서의 크기: (60,)\n",
            "[57 15  7 40 30 12 46 51 59 54 49 43 22 50  3 28  8  2 19 35  6  1 29 44\n",
            " 58 26 39 45 17 34 41 10 25 16 36  5 32 48 56 14 23  4 38 21 11 27 42 53\n",
            " 18 47  0  9 37 33 55 13 52 31 24 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3g3yLU--oMM"
      },
      "source": [
        "#훈련데이터와 검증데이터 분리\n",
        "x_train = data[validation_ratio:] # 훈련데이터의 70%를 훈련데이터\n",
        "y_train = labels[validation_ratio:] # 훈련데이터의 70%를 훈련데이터 Label (data와 labels는 같은 순서)\n",
        "x_val = data[:validation_ratio] # 훈련데이터의 30%를 검증데이터\n",
        "y_val = labels[:validation_ratio] # 훈련데이터의 30%를 검증데이터 Label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZstJIA8o-t9t"
      },
      "source": [
        "#모델 정의하기\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential() # 모델을 새로 정의\n",
        "model.add(Dense(64, activation='relu', input_shape=(max_words,))) # 첫 번째 은닉층. activation은 다음 층으로 값을 넘기는 방법\n",
        "model.add(Dense(32, activation='relu')) # 두 번째 은닉층\n",
        "model.add(Dense(1, activation='sigmoid')) # 출력층\n",
        "# 이진분류 문제이고 신경망의 출력이 확률로 나와야 하므로,\n",
        "# 0~1로 출력하는 sigmoid를 택하고, 노드는 1개로 하였다\n",
        "# 다중분류에서는 softmax를 사용한다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7XEqRHO-46n",
        "outputId": "212f918f-40d0-4e78-e4ac-253e7e0b82f5"
      },
      "source": [
        "#모델 요약 출력\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                640064    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 642,177\n",
            "Trainable params: 642,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-SiDKua_ote",
        "outputId": "e09cdfd5-cf6d-4329-9ce0-d4ad97840a8f"
      },
      "source": [
        "#Compile & Train Model\n",
        "# 모델 컴파일\n",
        "# 신경망의 출력이 확률이므로 오차값 계산은 crossentropy를 사용하는 것이 최선이다. https://keras.io/losses/ 에서 종류 참조\n",
        "# 또한 이진 분류이므로 binary_crossentropy를 사용한다. 다중 분류에서는 categorical_crossentropy를 사용한다\n",
        "# 가중치 업데이트 방법은 RMSprop을 사용하였다. https://keras.io/optimizers/ 에서 종류 참조\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "# 모델 훈련\n",
        "# 32개씩 미니 배치를 만들어 10번의 epoch로 훈련한다. 보통 8 ~ 512개 중에서 찾는다\n",
        "# 훈련 데이터로 훈련하고, 검증 데이터로 검증한다\n",
        "# 반환값의 history는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리이다\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 186ms/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6866 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4847 - acc: 0.9524 - val_loss: 0.6348 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3174 - acc: 1.0000 - val_loss: 0.6094 - val_acc: 0.6667\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2020 - acc: 1.0000 - val_loss: 0.5888 - val_acc: 0.6667\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1361 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.6111\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0937 - acc: 1.0000 - val_loss: 0.5411 - val_acc: 0.6667\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0678 - acc: 1.0000 - val_loss: 0.5588 - val_acc: 0.6111\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0523 - acc: 1.0000 - val_loss: 0.5546 - val_acc: 0.6111\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.5231 - val_acc: 0.6667\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.5117 - val_acc: 0.6667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cPUUaC__v-C",
        "outputId": "2b470805-d0e8-41bd-c0b3-30ac4f04a11c"
      },
      "source": [
        "#경로 변경\n",
        "# 파일이 있는 곳으로 경로를 변경한다\n",
        "%cd /content/gdrive/MyDrive/pytest/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/pytest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtDsKwN4_0yQ",
        "outputId": "5b14827b-c6d0-44bf-d1d8-f9fbbe005b2e"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m네이버뉴스-생활문화_다중\u001b[0m/  \u001b[01;34mkor-eng\u001b[0m/      pytest_position.png  test.csv\n",
            "\u001b[01;34maclImdb_v1_small\u001b[0m/          negative.txt  ratings_morphed.txt  김소월시.txt\n",
            "alice.png                  newfile2.txt  ratings_small.txt    윤동주시.txt\n",
            "\u001b[01;34mfra-eng\u001b[0m/                   newfile.csv   ratings.txt          wiki_test.txt\n",
            "iris.csv                   positive.txt  \u001b[01;34msimilarity\u001b[0m/          \u001b[01;34mword2vec\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zji04aua__3g"
      },
      "source": [
        "#Save Model\n",
        "# multidimensional numpy arrays를 저장할 수 있는 h5 file(HDF) 포맷으로 저장한다\n",
        "model.save('text_binary_model.h5')\n",
        "# 훈련데이터에서 사용된 상위빈도 10,000개의 단어로 된 Tokenizer 저장\n",
        "# 새로 입력되는 문장에서도 같은 단어가 추출되게 한다\n",
        "import pickle\n",
        "with open('text_binary_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK3jJRB1AQwW",
        "outputId": "ce70d4ce-4fa4-4b9f-b435-b0706b37a6aa"
      },
      "source": [
        "#Accuracy & Loss 확인\n",
        "# history 딕셔너리 안에 있는 정확도와 손실값을 가져와 본다\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "print('Accuracy of each epoch:', acc) # [0.79, 0.90, 0.93, 0.94, 0.96, 0.97, 0.98, 0.98, 0.98, 0.99]\n",
        "epochs = range(1, len(acc) +1) # range(1, 11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of each epoch: [0.5, 0.9523809552192688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "ZziKVx94F8md",
        "outputId": "b2f0b550-b5d9-49bb-8a85-03879382cb3f"
      },
      "source": [
        "#Plotting Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 훈련데이터의 정확도에 비해 검증데이터의 정확도는 낮게 나타난다\n",
        "# epoch가 늘어나면 모델은 훈련데이터에 매우 민감해져(과대적합) 오히려 새로운 데이터를 잘 못 맞춘다\n",
        "plt.plot(epochs, acc, 'bo', label='Training Acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5e14ff4690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "do3mg-y7GFlE",
        "outputId": "7c9a9426-5e1c-4e00-b391-7104c1758211"
      },
      "source": [
        "#Plotting Loss\n",
        "plt.figure() # 새로운 그림을 그린다\n",
        "\n",
        "# 훈련데이터의 손실값은 낮아지나, 검증데이터의 손실값은 높아진다\n",
        "# 손실값은 오류값을 말한다. 예측과 정답의 차이를 거리 계산으로 구한 값이다\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH5nAxjJGNnv",
        "outputId": "ae92fab7-7673-49cf-99f1-e3ab3cd0cd1b"
      },
      "source": [
        "#Load Model\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "filepath = '/content/gdrive/My Drive/pytest/'\n",
        "os.chdir(filepath)\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "\n",
        "loaded_model = load_model('text_binary_model.h5')\n",
        "print(\"model loaded:\", loaded_model)\n",
        "\n",
        "with open('text_binary_tokenizer.pickle', 'rb') as handle:\n",
        "    loaded_tokenizer = pickle.load(handle)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Directory: /content/gdrive/My Drive/pytest\n",
            "model loaded: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f5e1472b950>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkvB2wqVGloj"
      },
      "source": [
        "#Test Data Loading\n",
        "test_dir = os.path.join(imdb_dir, 'test') # aclimdb 폴더의 테스트 데이터 내용을 가져온다\n",
        "labels = [] ; texts = [] # labels와 texts 라는 두 개의 빈 리스트를 만든다\n",
        "\n",
        "for label_type in ['neg', 'pos']: # test 폴더에 있는 pos 12,500 + neg 12,500 개의 데이터를 읽는다\n",
        "    dir_name = os.path.join(test_dir, label_type) # neg와 pos 폴더 각각에 접근한다\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt': # 마지막 4 글자가 .txt 로 끝나는지를 확인한다\n",
        "            f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
        "            texts.append(f.read()) # 텍스트를 읽어서 texts 리스트에 연결한다\n",
        "            f.close()\n",
        "            if label_type == 'neg': # 만약 현재 폴더가 neg 폴더라면\n",
        "                labels.append(0) # texts와 같은 순서의 labels 리스트에는 0을 저장한다\n",
        "            else:\n",
        "                labels.append(1) # pos 폴더라면 같은 순서의 labels 리스트에 1을 저장\n",
        "#여기서 validation data는 최적 epochs를 찾는 데 사용되고, test data는 최적 epochs로 만들어진 모델의 성능을 평가하는 데 사용된다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-SUxmmRG6NE",
        "outputId": "9aa1c8fa-8106-454c-e811-7c60f9c77f35"
      },
      "source": [
        "#Data 확인\n",
        "print('texts:', texts[0])\n",
        "print('texts len:', len(texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "texts: Alas, another Costner movie that was an hour too long. Credible performances, but the script had no where to go and was in no hurry to get there. First we are offered an unrelated string of events few of which further the story. Will the script center on Randall and his wife? Randall and Fischer? How about Fischer and Thomas? In the end, no real front story ever develops and the characters themselves are artificially propped up by monologues from third parties. The singer explains Randall, Randall explains Fischer, on and on. Finally, long after you don't care anymore, you will learn something about the script meetings. Three endings were no doubt proffered and no one could make a decision. The end result? All three were used, one, after another, after another. If you can hang in past the 100th yawn, you'll be able to pick them out. Despite the transparent attempt to gain points with a dedication to the Coast Guard, this one should have washed out the very first day.\n",
            "texts len: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUIqYhFrG_ti"
      },
      "source": [
        "#Data Sequencing\n",
        "# 문자열을 word_index의 숫자 리스트로 변환\n",
        "data = loaded_tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# padding으로 문자열의 길이를 고정시킨다\n",
        "data = pad_sequences(data, maxlen=maxlen) \n",
        "\n",
        "# test 데이터를 원-핫 인코딩한다\n",
        "x_test = to_one_hot(data, dimension=max_words)\n",
        "\n",
        "# label을 list에서 넘파이 배열로 변환. 결과가 0 또는 1만 나오므로 이와같이 int32로 저장해도 된다\n",
        "# 다중분류에서는 이 부분도 원-핫 인코딩 한다\n",
        "y_test = np.asarray(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwugS_8NICdJ",
        "outputId": "e869a3f3-e01c-4ac2-8e46-aa0129f2d332"
      },
      "source": [
        "#Test Data Evaluation\n",
        "test_eval = loaded_model.evaluate(x_test, y_test) # 모델에 분류할 데이터와 그 정답을 같이 넣어준다\n",
        "print('prediction model loss & acc:', test_eval) # 모델이 분류한 결과와 입력된 정답을 비교한 결과\n",
        "\n",
        "#최적 epoch를 적용하지 않고 사용한 모델의 정확도"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 0.7442 - acc: 0.4500\n",
            "prediction model loss & acc: [0.7442428469657898, 0.44999998807907104]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG_zGRy0IMUh",
        "outputId": "f2cae8b2-effb-42ca-9164-873a925367f1"
      },
      "source": [
        "#1개 데이터 예측\n",
        "text = [\"Hi, this is a test sentence.\"] # 데이터를 list 타입으로 만든다\n",
        "data = loaded_tokenizer.texts_to_sequences(text)\n",
        "data = pad_sequences(data, maxlen=maxlen)\n",
        "x_test = to_one_hot(data, dimension=max_words)\n",
        "prediction = loaded_model.predict(x_test)\n",
        "print(\"Result:\", prediction) # [[0.57845604]]. 1이 될 확률이 57.8%\n",
        "# 다중 분류에서는 다음과 같이 넘파이의 함수를 이용해 가장 큰 값을 찾는다\n",
        "# print(\" Result :\", np.argmax(predictions[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: [[0.4698751]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y68T7CL4IarP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}